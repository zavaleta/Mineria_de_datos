{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0096fdc-2fc7-4401-837d-a4f2dddfdb2e",
   "metadata": {},
   "source": [
    "![logo](images/untumbes.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087ff36-6103-41c3-bdbf-04d1c15899ce",
   "metadata": {},
   "source": [
    "<center><b>Prof. Dr. Jorge Zavaleta - zavaleta.jorge@gmail.com</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144e0d43-829a-468b-9231-bb38d858827b",
   "metadata": {},
   "source": [
    "## Algoritmo de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40047bc0-35b4-4916-bc2c-9c651e1359e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librarys\n",
    "import numpy as np                          # calculo cientifico\n",
    "import pandas as pd                         # manejo de dataframes\n",
    "# graphics\n",
    "import matplotlib.pyplot as plt             # visualizacion grafica\n",
    "import seaborn as sns                       # visualizacion grafica\n",
    "#\n",
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "# analise de resultado - metricas\n",
    "#from sklearn.metrics import plot_confusion_matrix #deprecated\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import r2_score as R2\n",
    "#Modelagem com AI\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "#\n",
    "#import shap\n",
    "# path\n",
    "import os.path\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7fe34-92ae-4033-bbfb-4c7f8aaa0c2d",
   "metadata": {},
   "source": [
    ">## Lectura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a74a831-f845-436e-b2dc-29e2d186fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "path_dataset ='data/'    # diretorio do dataset local\n",
    "# dataset read\n",
    "file_name='curados_obitos_final.csv'          # nome do dataset\n",
    "data = pd.read_csv(path_dataset+file_name,sep=';',encoding='utf-8',low_memory=False) #index_col=0  #encoding='ISO-8859-1','latin-1')     # leitura do dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81642483-fb1f-4eae-84e9-48930f941670",
   "metadata": {},
   "source": [
    ">## Funciones y procedimientos auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024941e9-60a1-4f7b-8be6-1900418514e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create/write text file\n",
    "def write_file_text(filename,text):\n",
    "    #file exist\n",
    "    file_exist = os.path.isfile(filename)\n",
    "    if file_exist == False:\n",
    "        with open(filename,'w') as file:\n",
    "            file.write(text+'\\n')\n",
    "            file.write('------------------------------\\n')\n",
    "    else:\n",
    "        with open(filename,'a') as file:\n",
    "            file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a198b9-9cdf-4b9f-a75c-64de9d189ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "def display_cm(cm,class_names,title,fig_name):\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=class_names)\n",
    "    fig,ax = plt.subplots(figsize=(8,8))\n",
    "    disp.plot(ax=ax,cmap='Blues') #, xticks_rotation='vertical')\n",
    "    disp.ax_.set_title(title)\n",
    "    #plt.xlabel('Predicted')\n",
    "    #plt.ylabel('True')\n",
    "    plt.show()\n",
    "    fig.savefig('metricas/'+fig_name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97064c1b-4b31-40d3-8433-6d079a8fde3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve\n",
    "def plot_roc_curve(fpr,tpr,roc_auc,fig_name):\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    ax.plot(fpr, tpr, color='darkorange', lw=2,label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    ax.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    fig.savefig('metricas/'+fig_name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f23586-e12b-4c5b-8df9-3c38f3f9cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construir as distribuições - notebook kaggle - KAIKE WESLEY REIS\n",
    "def construir_distribuicoes(data,variaveis, objetivo=None, usar_objetivo=False):\n",
    "    # Definindo figura para construir gráficos\n",
    "    fig, axes = plt.subplots(nrows=int(len(variaveis)/2+1), ncols=2, figsize=(12,30))\n",
    "    \n",
    "    # Indexadores\n",
    "    r = 0      # Linha\n",
    "    c = 0      # Coluna\n",
    "\n",
    "    # Loop em todas as variaveis\n",
    "    for v in variaveis:\n",
    "        # Realizar gráfico de distribuicao\n",
    "        if usar_objetivo is False:\n",
    "            sns.kdeplot(data[v], shade=True, color='#50c878', ax=axes[r][c])\n",
    "        else:\n",
    "            sns.kdeplot(data.loc[data[objetivo] == 0, v], shade=True, color='#386796', ax=axes[r][c], label='Óbito')\n",
    "            sns.kdeplot(data.loc[data[objetivo] == 1, v], shade=True, color='#F06C61', ax=axes[r][c], label='Cura')\n",
    "            # Gerar legenda\n",
    "            axes[r][c].legend(title=objetivo)\n",
    "            pass\n",
    "        \n",
    "        # Aplicar configuracao do gráfico - gerais\n",
    "        axes[r][c].set_title('Variável - ' + v)   \n",
    "        axes[r][c].set_xlabel('')\n",
    "        \n",
    "        # Controle dos indexadores\n",
    "        c += 1\n",
    "        if c > 1:\n",
    "            c = 0\n",
    "            r += 1\n",
    "    # gravar os graficos\n",
    "    if usar_objetivo == False:\n",
    "        fig.savefig('metricas/distribuicao_covid_19.png')\n",
    "    else:\n",
    "        fig.savefig('metricas/estratificacao_covid_19.png')\n",
    "    # Configuracao básica de gráfico\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7c2f72-bdc4-49fa-9b5f-19da971fd631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construir as distribuições - notebook kaggle - KAIKE WESLEY REIS\n",
    "def construir_distribuicoes(data,variaveis, objetivo=None, usar_objetivo=False):\n",
    "    # Definindo figura para construir gráficos\n",
    "    fig, axes = plt.subplots(nrows=int(len(variaveis)/2+1), ncols=2, figsize=(12,30))\n",
    "    \n",
    "    # Indexadores\n",
    "    r = 0      # Linha\n",
    "    c = 0      # Coluna\n",
    "\n",
    "    # Loop em todas as variaveis\n",
    "    for v in variaveis:\n",
    "        # Realizar gráfico de distribuicao\n",
    "        if usar_objetivo is False:\n",
    "            sns.kdeplot(data[v], shade=True, color='#50c878', ax=axes[r][c])\n",
    "        else:\n",
    "            sns.kdeplot(data.loc[data[objetivo] == 0, v], shade=True, color='#386796', ax=axes[r][c], label='Óbito')\n",
    "            sns.kdeplot(data.loc[data[objetivo] == 1, v], shade=True, color='#F06C61', ax=axes[r][c], label='Cura')\n",
    "            # Gerar legenda\n",
    "            axes[r][c].legend(title=objetivo)\n",
    "            pass\n",
    "        \n",
    "        # Aplicar configuracao do gráfico - gerais\n",
    "        axes[r][c].set_title('Variável - ' + v)   \n",
    "        axes[r][c].set_xlabel('')\n",
    "        \n",
    "        # Controle dos indexadores\n",
    "        c += 1\n",
    "        if c > 1:\n",
    "            c = 0\n",
    "            r += 1\n",
    "    # gravar os graficos\n",
    "    if usar_objetivo == False:\n",
    "        fig.savefig('metricas/distribuicao_covid_19.png')\n",
    "    else:\n",
    "        fig.savefig('metricas/estratificacao_covid_19.png')\n",
    "    # Configuracao básica de gráfico\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d7fef-94c7-46a9-880a-e6c0689fd4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## spearman correlation\n",
    "# spearman correlationrafic\n",
    "def calcular_correlacao_numerica(data,variaveis, corr_tipo='spearman'):\n",
    "    return data[variaveis].corr(corr_tipo)\n",
    "#\n",
    "def plot_mapa_calor_corr(corr_matrix, titulo):    \n",
    "    # Fazer mascara para evitar correlação espelho\n",
    "    mascara = np.triu(corr_matrix)\n",
    "    # Fazer go\n",
    "    plt.figure(figsize=(20, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    sns.heatmap(corr_matrix, annot = True, mask=mascara, fmt='.2f', vmin=-1, vmax=1)\n",
    "    #plt.xticks(rotation=60)\n",
    "    plt.title(titulo, fontsize=25, fontweight='bold')\n",
    "    plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ab905-130f-4c9d-8d4e-11b4030ca276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avaliação de métricas\n",
    "def evaluate_metrics(y, y_pred):\n",
    "    #\n",
    "    mae = MAE(y, y_pred)\n",
    "    mse = MSE(y, y_pred)\n",
    "    rmse = mse ** (1/2)\n",
    "    r2 = R2(y, y_pred)\n",
    "    #\n",
    "    print(' Metricas da regresión')\n",
    "    print(f\" MAE: {mae:.2f}\")\n",
    "    print(f\" MSE: {mse:.2f}\")\n",
    "    print(f\" RMSE: {rmse:.2f}\")\n",
    "    print(f\" R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50356a0f-dd07-4dac-91fa-a5686d0574af",
   "metadata": {},
   "source": [
    "> # Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190bbd40-7a0e-45a0-b4b2-c8ac9a7cb1cd",
   "metadata": {},
   "source": [
    ">## Definición de las caracteristicas y el objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac68ab89-9c19-406b-9183-fe245dc32dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição de grupos de variáveis (features) e objetivo\n",
    "features = ['NU_IDADE_N', 'FEBRE', 'TOSSE', 'DISPNEIA', 'DESC_RESP','SATURACAO', 'VOMITO', 'FADIGA', 'OUTRO_SIN', \n",
    "            'FATOR_RISC', 'CARDIOPATI','ASMA', 'DIABETES', 'OUT_MORBI','VACINA_COV', 'UTI']\n",
    "objetivo = 'EVOLUCAO'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a79417-53d8-475e-b7fd-b9c261c2d8c9",
   "metadata": {},
   "source": [
    ">## Análisis exploratório de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a842f-cb10-4fdc-a764-2e236bcdd50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d377a-c946-4827-ab16-632c62804ecf",
   "metadata": {},
   "source": [
    ">## División de los datos para entrenamiento y teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ae5b1-baf5-40df-b766-903a5fc63752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treino e teste: ok\n",
    "#X = dados.iloc[:,0:21]\n",
    "#y = dados.iloc[:,21]\n",
    "# Definindo conjunto X e Y\n",
    "X = data.drop(axis=1, columns=[objetivo]).copy()  # todas las columnas menos la columna ´EVOLUCAO´\n",
    "y = data[objetivo].copy()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585eb079-11e1-4a37-8f09-f3ad0da4adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo a divisão estratificada 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0dab7-ac9a-4542-be35-ff863342a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza os dados de treinamento (X_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f90b9e1-8710-461e-94c0-ff790943409a",
   "metadata": {},
   "source": [
    ">## Balanceamiento de los datos de entrenamiento y teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2649282-7c42-41e7-becd-0073787143f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando balaceamento da variavel objetivo\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b14d8-2d66-456e-8f3d-1896109748b3",
   "metadata": {},
   "source": [
    "># Construcción del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb290632-e26d-4729-8803-da108ad20828",
   "metadata": {},
   "source": [
    ">## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a908e0e-acbe-417b-a3d7-be3f62c76693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  GridSearachCV Shapley\n",
    "def hiperparameters_mlp_gridSearchCV(X_train,y_train, X_test, y_test, params, filename, name):\n",
    "    \n",
    "    # create model\n",
    "    mlp_model = MLPClassifier(random_state=0, max_iter=100, early_stopping=True)\n",
    "\n",
    "    #\n",
    "    gs_mlp = GridSearchCV(estimator = mlp_model,\n",
    "                      param_grid=params,\n",
    "                      cv = 5,\n",
    "                      scoring=['f1', 'accuracy', 'recall', 'roc_auc',  'precision'],\n",
    "                      refit = 'accuracy')\n",
    "    # predict\n",
    "    DTC_MLP = gs_mlp.fit(X_train,y_train)\n",
    "     \n",
    "    # write file text\n",
    "    text0 ='File create by Jorge Zavaleta'\n",
    "    write_file_text(filename,text0)\n",
    "\n",
    "    # All results\n",
    "    means1 = DTC_MLP.cv_results_['mean_test_accuracy']\n",
    "    means2 = DTC_MLP.cv_results_['mean_test_precision']\n",
    "    means3 = DTC_MLP.cv_results_['mean_test_recall']\n",
    "    means4 = DTC_MLP.cv_results_['mean_test_f1']\n",
    "    means5 = DTC_MLP.cv_results_['mean_test_roc_auc']\n",
    "    stds = DTC_MLP.cv_results_['std_test_f1']\n",
    "    #\n",
    "    for mean1,mean2,mean3,mean4,mean5,std,params in zip(means1,means2,means3,means4,means5,stds,DTC_MLP.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean4, std * 2, params))\n",
    "        write_file_text(filename,' Acurácia: %0.3f ' % mean1)\n",
    "        write_file_text(filename,' Precision: %0.3f ' % mean2)\n",
    "        write_file_text(filename,' Recall: %0.3f ' % mean3)\n",
    "        write_file_text(filename,' F1-score: %0.3f ' % mean4)\n",
    "        write_file_text(filename,' ROC_AUC: %0.3f ' % mean5)\n",
    "        std = std*2\n",
    "        write_file_text(filename,' desvio: (+/-%0.03f) ' % std)\n",
    "        write_file_text(filename,' param: %s ' % params)\n",
    "        write_file_text(filename,'\\n')\n",
    "\n",
    "    # best parametes\n",
    "    print(' Best parameters found for MLP:\\n', DTC_MLP.best_params_)\n",
    "    #\n",
    "    write_file_text(filename,' \\nBest parameters found for MLP: %s' % DTC_MLP.best_params_)\n",
    "    write_file_text(filename,'\\n')\n",
    "    #\n",
    "    # evaluate model performance\n",
    "    #Y\n",
    "    #y_true = y_test\n",
    "    y_pred = DTC_MLP.predict(X_test)\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    #\n",
    "    print('MLP - Results on the test set:')\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "    # Score method also evaluates accuracy for classification models.\n",
    "    # accuracy\n",
    "    acc = accuracy_score(y_test, y_pred,normalize=True)\n",
    "    #precision\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    #fi-score\n",
    "    f1 = f1_score(y_test, y_pred, average='micro') \n",
    "    #recall/sensitivity   \t\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    #confusion matrix\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    # visualizar matriz de confusão\n",
    "    \n",
    "    print()\n",
    "    # print the scores\n",
    "    print(\" Accuracy:\", acc)\n",
    "    print(\" Precision:\", precision)\n",
    "    print(\" Recall/Sensitivity:\", recall)    \n",
    "    print(\" F1-score:\", f1)\n",
    "    print(\" cm:\\n\", cm)\n",
    "    #print(pd.DataFrame(confusion_matrix(y_test,y_pred, labels=np.unique(y_test)), index=['Óbito-0', 'Cura-1'], columns=['Predito-0', 'Predito-1']))\n",
    "\n",
    "    #write scores in the file text\n",
    "    write_file_text(filename,' \\nTraining Accuracy : {:.3f}'.format(DTC_MLP.score(X_train, y_train)))\n",
    "    write_file_text(filename,' \\nTest Accuracy : {:.3f}'.format(DTC_MLP.score(X_test,y_test))+'\\n\\n')\n",
    "    #\n",
    "    write_file_text(filename,' Classification Report of MLP:\\n')\n",
    "    write_file_text(filename, classification_report(y_test,y_pred)+\"\\n\")\n",
    "    write_file_text(filename,' Resultado do test set for MLP:\\n')\n",
    "    write_file_text(filename,'\\n Accuracy: %0.03f' % acc)\n",
    "    write_file_text(filename,'\\n Precision: %0.03f' % precision)\n",
    "    write_file_text(filename,'\\n Recall: %0.03f' % recall)\n",
    "    write_file_text(filename,'\\n F1-score: %0.03f\\n' % f1)\n",
    "    write_file_text(filename,'\\n Matriz de confusao:\\n')\n",
    "    write_file_text(filename,' %0.03f ' % cm[0][0])\n",
    "    write_file_text(filename,' %0.03f \\n' % cm[0][1])\n",
    "    write_file_text(filename,' %0.03f ' % cm[1][0])\n",
    "    write_file_text(filename,' %0.03f ' % cm[1][1])\n",
    "    write_file_text(filename,'\\n\\n')\n",
    "    #\n",
    "    print()\n",
    "\n",
    "    # classes\n",
    "    class_names=[]\n",
    "    class_names.append(\"Óbito\")\n",
    "    class_names.append(\"Cura\")\n",
    "    \n",
    "    # plot the confusion matrix, without normalization\n",
    "    title1 = \"Confusion matrix, without normalization\"\n",
    "    print('Graphic of the '+title1)\n",
    "    #\n",
    "    fig_name1 = 'data_mlp_matriz_confusao'\n",
    "    display_cm(cm,class_names,title1,fig_name1)\n",
    "    \n",
    "    # Normalized confusion matrix\n",
    "    title2 = 'Normalized confusion matrix'\n",
    "    cm_normalized = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "    #\n",
    "    print(title2+'\\n')\n",
    "    print(' %0.03f ' % cm_normalized[0][0],' %0.03f ' % cm_normalized[0][1])\n",
    "    #print('%0.03f ' % cm_normalized[0][1])\n",
    "    print(' %0.03f ' % cm_normalized[1][0],' %0.03f ' % cm_normalized[1][1])\n",
    "    #print(' %0.03f ' % cm_normalized[1][1])\n",
    "    print('\\n')\n",
    "    # write file\n",
    "    write_file_text(filename,title2+'\\n')\n",
    "    write_file_text(filename,' %0.03f ' % cm_normalized[0][0])\n",
    "    write_file_text(filename,' %0.03f \\n' % cm_normalized[0][1])\n",
    "    write_file_text(filename,' %0.03f ' % cm_normalized[1][0])\n",
    "    write_file_text(filename,' %0.03f ' % cm_normalized[1][1])\n",
    "    write_file_text(filename,'\\n\\n')\n",
    "    #\n",
    "    print(' Graphic of the '+title2)\n",
    "    #\n",
    "    fig_name2 = 'data_mlp_matriz_confusao_normalized'\n",
    "    display_cm(cm_normalized,class_names,title2,fig_name2)\n",
    "    \n",
    "    #\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr, tpr, _  = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #\n",
    "    print(' ROC curve (area = %0.2f)' % roc_auc+'\\n')\n",
    "    write_file_text(filename,' ROC curve (area = %0.2f)' % roc_auc+'\\n')\n",
    "    #\n",
    "    print(' Graphic of the ROC curve\\n')\n",
    "    #\n",
    "    fig_name = 'data_mlp_curva_roc'\n",
    "    plot_roc_curve(fpr,tpr,roc_auc,fig_name)\n",
    "\n",
    "        # Vamos calcular o resultado de probabilidade de predição do conjunto de treino\n",
    "    y_pred_train_proba = DTC_MLP.predict_proba(X_train)\n",
    "    #\n",
    "    # Vamos agora selecionar um resultado que previu como positivo\n",
    "    print(' Probabilidade do modelo prever negativo -',100*y_pred_train_proba[3][0].round(2),'%.')\n",
    "    print(' Probabilidade do modelo prever positivo -',100*y_pred_train_proba[3][1].round(2),'%.')\n",
    "\n",
    "    \n",
    "    # Vamos calcular o resultado de probabilidade de predição do conjunto de treino\n",
    "    y_pred_test_proba = DTC_MLP.predict_proba(X_test)\n",
    "    #\n",
    "    # Vamos agora selecionar um resultado que previu como positivo\n",
    "    print('Test - Probabilidade do modelo prever negativo -',100*y_pred_test_proba[3][0].round(2),'%.')\n",
    "    print('test - Probabilidade do modelo prever positivo -',100*y_pred_test_proba[3][1].round(2),'%.')\n",
    "\n",
    "    #\n",
    "    print()\n",
    "    print(' Evaluación de las métricas de regresión para MLP:\\n')\n",
    "    evaluate_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab7faa-4431-44cb-bacb-bee55fa85146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp\n",
    "mlp_name=['MLP Vacinas COVID-19']\n",
    "mlp_params=[{'hidden_layer_sizes': [5, 10, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100], \n",
    " \t\t'activation': ['relu','tanh'],\n",
    " \t\t'solver': ['adam', 'sgd','lbfgs'],\n",
    " \t\t'alpha': [0.001, 0.05],\n",
    " \t\t'learning_rate': ['constant','adaptive'],\n",
    " \t\t'nesterovs_momentum': [True, False], \n",
    " \t\t'beta_1': [0.95], 'beta_2': [0.999],\n",
    " \t\t'learning_rate_init': [0.0001, 0.005, 0.001, 0.05],\n",
    " \t\t'momentum': [0.9, 0.95]}]\n",
    "#\n",
    "# mlp_params =[{'activation': ['relu'], \n",
    "#              'alpha': [0.001], \n",
    "#              'beta_1': [0.95], \n",
    "#              'beta_2': [0.999], \n",
    "#              'hidden_layer_sizes': [10], \n",
    "#              'learning_rate': ['constant'], \n",
    "#              'learning_rate_init': [0.0001], \n",
    "#              'momentum': [0.9], \n",
    "#              'nesterovs_momentum': [True], \n",
    "#              'solver': ['lbfgs']}]\n",
    "\n",
    "\n",
    "mlp_filename = 'metricas/data_mlp.txt'\n",
    "hiperparameters_mlp_gridSearchCV(X_train,y_train, X_test, y_test, mlp_params, mlp_filename, mlp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100cf515-e00a-411b-a6c1-d334df734ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5d9ad2-6162-4024-ba1f-26ce27c8a27c",
   "metadata": {},
   "source": [
    "<center><b>© Jorge Zavaleta, 2024</b></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
