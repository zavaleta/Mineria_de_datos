{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a6490a2-7ed4-4e36-9ed6-0cbb393c7409",
   "metadata": {},
   "source": [
    "![logo](images/untumbes.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b162033-083f-4fe0-8d3f-aa2d417d11c7",
   "metadata": {},
   "source": [
    "<center><b>Prof. Dr. Jorge Zavaleta - zavaleta.jorge@gmail.com</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac2dade-89cf-4590-94af-139fc8637c81",
   "metadata": {},
   "source": [
    "## Algoritmo de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23570d3-0781-43e5-b978-ae95dbb60ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librarys\n",
    "import numpy as np                          # calculo cientifico\n",
    "import pandas as pd                         # manejo de dataframes\n",
    "# graphics\n",
    "import matplotlib.pyplot as plt             # visualizacion grafica\n",
    "import seaborn as sns                       # visualizacion grafica\n",
    "#\n",
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "# analise de resultado - metricas\n",
    "#from sklearn.metrics import plot_confusion_matrix #deprecated\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import r2_score as R2\n",
    "#Modelagem com AI\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "#\n",
    "#import shap\n",
    "# path\n",
    "import os.path\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f4c2c-caa2-4c3c-a3a8-db578ac5dd37",
   "metadata": {},
   "source": [
    ">## Lectura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44f85f-ffa3-4857-b17d-b52d3c808581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "path_dataset ='data/'    # diretorio do dataset local\n",
    "# dataset read\n",
    "file_name='curados_obitos_final.csv'          # nome do dataset\n",
    "data = pd.read_csv(path_dataset+file_name,sep=';',encoding='utf-8',low_memory=False) #index_col=0  #encoding='ISO-8859-1','latin-1')     # leitura do dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3474bf-b6e6-4855-bb7c-0e457d189ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58b43be9-50c3-4828-890b-7f59c58736ac",
   "metadata": {},
   "source": [
    ">## Funciones y procedimientos auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f2d56-f9ea-4c1e-a421-f1c59382b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create/write text file\n",
    "def write_file_text(filename,text):\n",
    "    #file exist\n",
    "    file_exist = os.path.isfile(filename)\n",
    "    if file_exist == False:\n",
    "        with open(filename,'w') as file:\n",
    "            file.write(text+'\\n')\n",
    "            file.write('------------------------------\\n')\n",
    "    else:\n",
    "        with open(filename,'a') as file:\n",
    "            file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d6ae99-9086-48f6-9706-4ec2203b422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "def display_cm(cm,class_names,title,fig_name):\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=class_names)\n",
    "    fig,ax = plt.subplots(figsize=(8,8))\n",
    "    disp.plot(ax=ax,cmap='Blues') #, xticks_rotation='vertical')\n",
    "    disp.ax_.set_title(title)\n",
    "    #plt.xlabel('Predicted')\n",
    "    #plt.ylabel('True')\n",
    "    plt.show()\n",
    "    fig.savefig('metricas/'+fig_name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e1311-4f57-454e-839a-aae6ff955b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve\n",
    "def plot_roc_curve(fpr,tpr,roc_auc,fig_name):\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    ax.plot(fpr, tpr, color='darkorange', lw=2,label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    ax.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    fig.savefig('metricas/'+fig_name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe070b99-fbc8-4ad5-a204-352b6c071f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construir as distribuições - notebook kaggle - KAIKE WESLEY REIS\n",
    "def construir_distribuicoes(data,variaveis, objetivo=None, usar_objetivo=False):\n",
    "    # Definindo figura para construir gráficos\n",
    "    fig, axes = plt.subplots(nrows=int(len(variaveis)/2+1), ncols=2, figsize=(12,30))\n",
    "    \n",
    "    # Indexadores\n",
    "    r = 0      # Linha\n",
    "    c = 0      # Coluna\n",
    "\n",
    "    # Loop em todas as variaveis\n",
    "    for v in variaveis:\n",
    "        # Realizar gráfico de distribuicao\n",
    "        if usar_objetivo is False:\n",
    "            sns.kdeplot(data[v], shade=True, color='#50c878', ax=axes[r][c])\n",
    "        else:\n",
    "            sns.kdeplot(data.loc[data[objetivo] == 0, v], shade=True, color='#386796', ax=axes[r][c], label='Óbito')\n",
    "            sns.kdeplot(data.loc[data[objetivo] == 1, v], shade=True, color='#F06C61', ax=axes[r][c], label='Cura')\n",
    "            # Gerar legenda\n",
    "            axes[r][c].legend(title=objetivo)\n",
    "            pass\n",
    "        \n",
    "        # Aplicar configuracao do gráfico - gerais\n",
    "        axes[r][c].set_title('Variável - ' + v)   \n",
    "        axes[r][c].set_xlabel('')\n",
    "        \n",
    "        # Controle dos indexadores\n",
    "        c += 1\n",
    "        if c > 1:\n",
    "            c = 0\n",
    "            r += 1\n",
    "    # gravar os graficos\n",
    "    if usar_objetivo == False:\n",
    "        fig.savefig('metricas/distribuicao_covid_19.png')\n",
    "    else:\n",
    "        fig.savefig('metricas/estratificacao_covid_19.png')\n",
    "    # Configuracao básica de gráfico\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4914d-8835-4208-a586-95059d797433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construir as distribuições - notebook kaggle - KAIKE WESLEY REIS\n",
    "def construir_distribuicoes(data,variaveis, objetivo=None, usar_objetivo=False):\n",
    "    # Definindo figura para construir gráficos\n",
    "    fig, axes = plt.subplots(nrows=int(len(variaveis)/2+1), ncols=2, figsize=(12,30))\n",
    "    \n",
    "    # Indexadores\n",
    "    r = 0      # Linha\n",
    "    c = 0      # Coluna\n",
    "\n",
    "    # Loop em todas as variaveis\n",
    "    for v in variaveis:\n",
    "        # Realizar gráfico de distribuicao\n",
    "        if usar_objetivo is False:\n",
    "            sns.kdeplot(data[v], shade=True, color='#50c878', ax=axes[r][c])\n",
    "        else:\n",
    "            sns.kdeplot(data.loc[data[objetivo] == 0, v], shade=True, color='#386796', ax=axes[r][c], label='Óbito')\n",
    "            sns.kdeplot(data.loc[data[objetivo] == 1, v], shade=True, color='#F06C61', ax=axes[r][c], label='Cura')\n",
    "            # Gerar legenda\n",
    "            axes[r][c].legend(title=objetivo)\n",
    "            pass\n",
    "        \n",
    "        # Aplicar configuracao do gráfico - gerais\n",
    "        axes[r][c].set_title('Variável - ' + v)   \n",
    "        axes[r][c].set_xlabel('')\n",
    "        \n",
    "        # Controle dos indexadores\n",
    "        c += 1\n",
    "        if c > 1:\n",
    "            c = 0\n",
    "            r += 1\n",
    "    # gravar os graficos\n",
    "    if usar_objetivo == False:\n",
    "        fig.savefig('metricas/distribuicao_covid_19.png')\n",
    "    else:\n",
    "        fig.savefig('metricas/estratificacao_covid_19.png')\n",
    "    # Configuracao básica de gráfico\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc54f8fb-4906-4558-97fe-013ecc1ec3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## spearman correlation\n",
    "# spearman correlationrafic\n",
    "def calcular_correlacao_numerica(data,variaveis, corr_tipo='spearman'):\n",
    "    return data[variaveis].corr(corr_tipo)\n",
    "#\n",
    "def plot_mapa_calor_corr(corr_matrix, titulo):    \n",
    "    # Fazer mascara para evitar correlação espelho\n",
    "    mascara = np.triu(corr_matrix)\n",
    "    # Fazer go\n",
    "    plt.figure(figsize=(20, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    sns.heatmap(corr_matrix, annot = True, mask=mascara, fmt='.2f', vmin=-1, vmax=1)\n",
    "    #plt.xticks(rotation=60)\n",
    "    plt.title(titulo, fontsize=25, fontweight='bold')\n",
    "    plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95639b5a-0041-422a-9d06-f567ad886601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avaliação de métricas\n",
    "def evaluate_metrics(y, y_pred):\n",
    "    #\n",
    "    mae = MAE(y, y_pred)\n",
    "    mse = MSE(y, y_pred)\n",
    "    rmse = mse ** (1/2)\n",
    "    r2 = R2(y, y_pred)\n",
    "    #\n",
    "    print(' Metricas da regresión')\n",
    "    print(f\" MAE: {mae:.2f}\")\n",
    "    print(f\" MSE: {mse:.2f}\")\n",
    "    print(f\" RMSE: {rmse:.2f}\")\n",
    "    print(f\" R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e385ed2-2aa9-4eec-baed-5a1b1afc35b6",
   "metadata": {},
   "source": [
    "># Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2f58f9-44b5-4359-ae75-7f8c7f5fdb43",
   "metadata": {},
   "source": [
    ">## Definición de las caracteristicas y el objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2d3653-39a6-4b0e-98f2-cd2cbf59b125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição de grupos de variáveis (features) e objetivo\n",
    "features = ['NU_IDADE_N', 'FEBRE', 'TOSSE', 'DISPNEIA', 'DESC_RESP','SATURACAO', 'VOMITO', 'FADIGA', 'OUTRO_SIN', \n",
    "            'FATOR_RISC', 'CARDIOPATI','ASMA', 'DIABETES', 'OUT_MORBI','VACINA_COV', 'UTI']\n",
    "objetivo = 'EVOLUCAO'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e6e143-ea36-4714-ac96-0b880b2949d1",
   "metadata": {},
   "source": [
    ">## Análisis exploratório de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed700182-cf73-4dcc-9f1c-cb67a57a599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58212e3d-a284-476a-a6bc-8a9e20c67d67",
   "metadata": {},
   "source": [
    ">## División de los datos para entrenamiento y teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8043ea5-304e-4020-ab37-215f996f6680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treino e teste: ok\n",
    "#X = dados.iloc[:,0:21]\n",
    "#y = dados.iloc[:,21]\n",
    "# Definindo conjunto X e Y\n",
    "X = data.drop(axis=1, columns=[objetivo]).copy()  # todas las columnas menos la columna ´EVOLUCAO´\n",
    "y = data[objetivo].copy()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c23e0-41e1-4b16-b756-99e8692c88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo a divisão estratificada 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573afb70-638e-4e07-9981-a6abece6535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza os dados de treinamento (X_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c64c1-98b2-4212-a658-00fa53dc09f1",
   "metadata": {},
   "source": [
    ">## Balanceamiento de los datos de entrenamiento y teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcd1284-de53-4a92-be26-87f4246ebb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando balaceamento da variavel objetivo\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fa647e-ea5f-445e-bb1a-a1a4301e58ac",
   "metadata": {},
   "source": [
    "># Construcción del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d962d7b2-6038-490d-abe8-643108e603eb",
   "metadata": {},
   "source": [
    ">## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d7604-12f0-4544-9304-3b0b7793137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "def hiperparameters_nb_gridSearchCV(X_train,y_train, X_test, y_test, params, filename, name):\n",
    "   \n",
    "    # create a categorical Naive Bayes Model\n",
    "    nb_model = CategoricalNB()\n",
    "    #\n",
    "    DTC_Grid = GridSearchCV(nb_model,param_grid=params, cv=5, \n",
    "                          scoring=['f1', 'accuracy', 'recall', 'roc_auc',  'precision'], \n",
    "                          refit='accuracy')\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    DTC_NB = DTC_Grid.fit(X_train,y_train)\n",
    "\n",
    "    # create file with information of the training data\n",
    "    text0 ='File create by Jorge Zavaleta'\n",
    "    write_file_text(filename,text0)\n",
    "\n",
    "    # print the all results\n",
    "    means1 = DTC_NB.cv_results_['mean_test_accuracy']\n",
    "    means2 = DTC_NB.cv_results_['mean_test_precision']\n",
    "    means3 = DTC_NB.cv_results_['mean_test_recall']\n",
    "    means4 = DTC_NB.cv_results_['mean_test_f1']\n",
    "    means5 = DTC_NB.cv_results_['mean_test_roc_auc']\n",
    "    stds = DTC_NB.cv_results_['std_test_f1']\n",
    "    # for\n",
    "    for mean1,mean2,mean3,mean4,mean5,std,params in zip(means1,means2,means3,means4,means5,stds,DTC_NB.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean4, std * 2, params))\n",
    "        write_file_text(filename,' Acurácia: %0.3f ' % mean1)\n",
    "        write_file_text(filename,' Precision: %0.3f ' % mean2)\n",
    "        write_file_text(filename,' Recall: %0.3f ' % mean3)\n",
    "        write_file_text(filename,' F1-score: %0.3f ' % mean4)\n",
    "        write_file_text(filename,' ROC_AUC: %0.3f ' % mean5)\n",
    "        std = std*2\n",
    "        write_file_text(filename,' desvio: (+/-%0.03f) ' % std)\n",
    "        write_file_text(filename,' param: %s ' % params)\n",
    "        write_file_text(filename,'\\n')\n",
    "\n",
    "    # Best parameters\n",
    "    print('Best parameters found:\\n', DTC_NB.best_params_)\n",
    "    #\n",
    "    write_file_text(filename,'Best parameters found: %s' % DTC_NB.best_params_)\n",
    "    write_file_text(filename,'\\n')\n",
    "\n",
    "    # evaluate model performance\n",
    "    #Y\n",
    "    #y_true = y_test\n",
    "    y_pred = DTC_NB.predict(X_test)\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    #\n",
    "    print(' Naive Bayes - Results on the test set:')\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "    # Score method also evaluates accuracy for classification models.\n",
    "    # accuracy\n",
    "    acc = accuracy_score(y_test, y_pred,normalize=True)\n",
    "    #precision\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    #fi-score\n",
    "    f1 = f1_score(y_test, y_pred, average='micro') \n",
    "    #recall/sensitivity   \t\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    #confusion matrix\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    # visualizar matriz de confusão\n",
    "    #print(pd.DataFrame(confusion_matrix(y_test,y_pred, labels=np.unique(y_test)), index=['Óbito-0', 'Cura-1'], columns=['Predito-0', 'Predito-1']))\n",
    "\n",
    "    print()\n",
    "    # print the scores\n",
    "    print(\" Accuracy:\", acc)\n",
    "    print(\" Precision:\", precision)\n",
    "    print(\" Recall/Sensitivity:\", recall)    \n",
    "    print(\" F1-score:\", f1)\n",
    "    print(\" cm:\\n\", cm)\n",
    "\n",
    "    #write scores in the file text\n",
    "    write_file_text(filename,' \\nTraining Accuracy : {:.3f}'.format(DTC_NB.score(X_train, y_train)))\n",
    "    write_file_text(filename,' \\nTest Accuracy : {:.3f}'.format(DTC_NB.score(X_test,y_test))+'\\n\\n')\n",
    "    #\n",
    "    write_file_text(filename,' Classification Report of Naive Bayes:\\n')\n",
    "    write_file_text(filename, classification_report(y_test,y_pred)+\"\\n\")\n",
    "    write_file_text(filename,' Resultado do test set:\\n')\n",
    "    write_file_text(filename,'\\n Accuracy: %0.03f' % acc)\n",
    "    write_file_text(filename,'\\n Precision: %0.03f' % precision)\n",
    "    write_file_text(filename,'\\n Recall: %0.03f' % recall)\n",
    "    write_file_text(filename,'\\n F1-score: %0.03f\\n' % f1)\n",
    "    write_file_text(filename,'\\n Matriz de confusao:\\n')\n",
    "    write_file_text(filename,' %0.03f ' % cm[0][0])\n",
    "    write_file_text(filename,' %0.03f \\n' % cm[0][1])\n",
    "    write_file_text(filename,' %0.03f ' % cm[1][0])\n",
    "    write_file_text(filename,' %0.03f ' % cm[1][1])\n",
    "    write_file_text(filename,'\\n\\n')\n",
    "    #\n",
    "    print()\n",
    "    #\n",
    "    class_names=[]\n",
    "    class_names.append(\"Óbito\")\n",
    "    class_names.append(\"Cura\")\n",
    "    #\n",
    "    # plot the confusion matrix, without normalization\n",
    "    title1 = \"Confusion matrix, without normalization\"\n",
    "    print('Graphic of the '+title1)\n",
    "    #\n",
    "    fig_name1 = 'data_nb_matriz_confusao'\n",
    "    display_cm(cm,class_names,title1,fig_name1)\n",
    "    \n",
    "    # Normalized confusion matrix\n",
    "    title2 = 'Normalized confusion matrix'\n",
    "    cm_normalized = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "    #\n",
    "    print(title2+'\\n')\n",
    "    print(' %0.03f ' % cm_normalized[0][0],' %0.03f ' % cm_normalized[0][1])\n",
    "    #print('%0.03f ' % cm_normalized[0][1])\n",
    "    print(' %0.03f ' % cm_normalized[1][0],' %0.03f ' % cm_normalized[1][1])\n",
    "    #print(' %0.03f ' % cm_normalized[1][1])\n",
    "    print('\\n')\n",
    "    # write file\n",
    "    write_file_text(filename,title2+'\\n')\n",
    "    write_file_text(filename,' %0.03f ' % cm_normalized[0][0])\n",
    "    write_file_text(filename,' %0.03f \\n' % cm_normalized[0][1])\n",
    "    write_file_text(filename,' %0.03f ' % cm_normalized[1][0])\n",
    "    write_file_text(filename,' %0.03f ' % cm_normalized[1][1])\n",
    "    write_file_text(filename,'\\n\\n')\n",
    "    #\n",
    "    print(' Graphic of the '+title2)\n",
    "    #\n",
    "    fig_name2 = 'data_nb_matriz_confusao_normalizada'\n",
    "    display_cm(cm_normalized,class_names,title2,fig_name2)\n",
    "    \n",
    "    #\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr, tpr, _  = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #\n",
    "    print(' ROC curve (area = %0.2f)' % roc_auc+'\\n')\n",
    "    write_file_text(filename,' ROC curve (area = %0.2f)' % roc_auc+'\\n')\n",
    "    #\n",
    "    print(' Graphic of the ROC curve\\n')\n",
    "    #\n",
    "    fig_name = 'data_nb_curva_roc'\n",
    "    plot_roc_curve(fpr,tpr,roc_auc,fig_name)\n",
    "\n",
    "    # Vamos calcular o resultado de probabilidade de predição do conjunto de treino\n",
    "    y_pred_train_proba = DTC_NB.predict_proba(X_train)\n",
    "    #\n",
    "    # Vamos agora selecionar um resultado que previu como positivo\n",
    "    print(' Probabilidad del modelo prever negativo -',100*y_pred_train_proba[3][0].round(2),'%.')\n",
    "    print(' Probabilidad del modelo prever positivo -',100*y_pred_train_proba[3][1].round(2),'%.')\n",
    "\n",
    "    # Vamos calcular o resultado de probabilidade de predição do conjunto de treino\n",
    "    y_pred_test_proba = DTC_NB.predict_proba(X_test)\n",
    "    #\n",
    "    # Vamos agora selecionar um resultado que previu como positivo\n",
    "    print('Test - Probabilidad del modelo prever negativo -',100*y_pred_test_proba[3][0].round(2),'%.')\n",
    "    print('test - Probabilidad del modelo prever positivo -',100*y_pred_test_proba[3][1].round(2),'%.')\n",
    "    #\n",
    "    print()\n",
    "    print(' Evaluación de los valores de las métricas de NB:\\n')\n",
    "    evaluate_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541a7d7-666b-4f6c-8dba-162e0e9c453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Categorical\n",
    "nb_name=['Naive Bayes Vacinas COVID-19']\n",
    "nb_params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, \n",
    "                   10.0, 20, 50, 100, 500, 1000]}\n",
    "#\n",
    "nb_filename = 'metricas/data_nb.txt'\n",
    "hiperparameters_nb_gridSearchCV(X_train,y_train, X_test, y_test, nb_params, nb_filename, nb_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb8c19-6c7b-4c99-b66a-3eacf4e16578",
   "metadata": {},
   "source": [
    "<center><b>© Jorge Zavaleta, 2024</b></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
