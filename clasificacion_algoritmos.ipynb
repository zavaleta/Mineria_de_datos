{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65dbae3f-18c2-4b99-a873-bc4ba35e1174",
   "metadata": {},
   "source": [
    "![logo](images/untumbes.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6efa6c5-1b6b-495d-9051-72101ddb3b74",
   "metadata": {},
   "source": [
    "<center><b>Prof. Dr. Jorge Zavaleta - zavaleta.jorge@gmail.com</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e86dc2-7055-455c-a131-feba9e2be0f9",
   "metadata": {},
   "source": [
    "## Algoritmos de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79938c33-c7be-4248-a7ed-be599fd9a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librarys\n",
    "import numpy as np                          # calculo cientifico\n",
    "import pandas as pd                         # manejo de dataframes\n",
    "# graphics\n",
    "import matplotlib.pyplot as plt             # visualizacion grafica\n",
    "import seaborn as sns                       # visualizacion grafica\n",
    "#\n",
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "# analise de resultado - metricas\n",
    "#from sklearn.metrics import plot_confusion_matrix #deprecated\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import r2_score as R2\n",
    "#Modelagem com AI\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "#\n",
    "#import shap\n",
    "# path\n",
    "import os.path\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6118342-1ff8-494f-9502-c5cb5a52f368",
   "metadata": {},
   "source": [
    ">## Lectura y visualización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25292494-33d1-453e-9937-6d9527bd00a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "path_dataset ='data/'    # diretorio do dataset local\n",
    "# dataset read\n",
    "file_name='curados_obitos_final.csv'          # nome do dataset\n",
    "data = pd.read_csv(path_dataset+file_name,sep=';',encoding='utf-8',low_memory=False) #index_col=0  #encoding='ISO-8859-1','latin-1')     # leitura do dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8cc7b7-2781-4a66-9ad5-f57df3a9fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b71a52-1fc0-44c2-9d2d-361f33ce67db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando as dimensões do dataset\n",
    "print('Dimensiones:',data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12417bc1-908e-4bdc-9fdc-5d3b15b2268c",
   "metadata": {},
   "source": [
    ">## Funciones y procedimientos auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6bb4b8-699e-45d1-b1b6-852d1dcee3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create/write text file\n",
    "def write_file_text(filename,text):\n",
    "    #file exist\n",
    "    file_exist = os.path.isfile(filename)\n",
    "    if file_exist == False:\n",
    "        with open(filename,'w') as file:\n",
    "            file.write(text+'\\n')\n",
    "            file.write('------------------------------\\n')\n",
    "    else:\n",
    "        with open(filename,'a') as file:\n",
    "            file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2122e-f8bf-428f-b340-3196845a235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "def display_cm(cm,class_names,title,fig_name):\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=class_names)\n",
    "    fig,ax = plt.subplots(figsize=(8,8))\n",
    "    disp.plot(ax=ax,cmap='Blues') #, xticks_rotation='vertical')\n",
    "    disp.ax_.set_title(title)\n",
    "    #plt.xlabel('Predicted')\n",
    "    #plt.ylabel('True')\n",
    "    plt.show()\n",
    "    fig.savefig('metricas/'+fig_name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc46b8-46df-4fe3-b8f3-acb1ee447aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve\n",
    "def plot_roc_curve(fpr,tpr,roc_auc,fig_name):\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    ax.plot(fpr, tpr, color='darkorange', lw=2,label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    ax.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    fig.savefig('metricas/'+fig_name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d9f6f4-3975-476c-8290-66067ff1926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construir as distribuições - notebook kaggle - KAIKE WESLEY REIS\n",
    "def construir_distribuicoes(data,variaveis, objetivo=None, usar_objetivo=False):\n",
    "    # Definindo figura para construir gráficos\n",
    "    fig, axes = plt.subplots(nrows=int(len(variaveis)/2+1), ncols=2, figsize=(12,30))\n",
    "    \n",
    "    # Indexadores\n",
    "    r = 0      # Linha\n",
    "    c = 0      # Coluna\n",
    "\n",
    "    # Loop em todas as variaveis\n",
    "    for v in variaveis:\n",
    "        # Realizar gráfico de distribuicao\n",
    "        if usar_objetivo is False:\n",
    "            sns.kdeplot(data[v], shade=True, color='#50c878', ax=axes[r][c])\n",
    "        else:\n",
    "            sns.kdeplot(data.loc[data[objetivo] == 0, v], shade=True, color='#386796', ax=axes[r][c], label='Óbito')\n",
    "            sns.kdeplot(data.loc[data[objetivo] == 1, v], shade=True, color='#F06C61', ax=axes[r][c], label='Cura')\n",
    "            # Gerar legenda\n",
    "            axes[r][c].legend(title=objetivo)\n",
    "            pass\n",
    "        \n",
    "        # Aplicar configuracao do gráfico - gerais\n",
    "        axes[r][c].set_title('Variável - ' + v)   \n",
    "        axes[r][c].set_xlabel('')\n",
    "        \n",
    "        # Controle dos indexadores\n",
    "        c += 1\n",
    "        if c > 1:\n",
    "            c = 0\n",
    "            r += 1\n",
    "    # gravar os graficos\n",
    "    if usar_objetivo == False:\n",
    "        fig.savefig('metricas/distribuicao_covid_19.png')\n",
    "    else:\n",
    "        fig.savefig('metricas/estratificacao_covid_19.png')\n",
    "    # Configuracao básica de gráfico\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea1247-1c51-4fde-ae1b-fcad71acab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## spearman correlation\n",
    "# spearman correlationrafic\n",
    "def calcular_correlacao_numerica(data,variaveis, corr_tipo='spearman'):\n",
    "    return data[variaveis].corr(corr_tipo)\n",
    "#\n",
    "def plot_mapa_calor_corr(corr_matrix, titulo):    \n",
    "    # Fazer mascara para evitar correlação espelho\n",
    "    mascara = np.triu(corr_matrix)\n",
    "    # Fazer go\n",
    "    plt.figure(figsize=(20, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    sns.heatmap(corr_matrix, annot = True, mask=mascara, fmt='.2f', vmin=-1, vmax=1)\n",
    "    #plt.xticks(rotation=60)\n",
    "    plt.title(titulo, fontsize=25, fontweight='bold')\n",
    "    plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60529421-e3a7-444d-a63e-f6aabdba58b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scatter \n",
    "def fazer_scatter_plot(data, col1, col2, color_by=None):\n",
    "    # Definir figura\n",
    "    plt.figure(figsize=(8,8))\n",
    "    # Escolher de acordo a variável\n",
    "    if color_by is None:   \n",
    "        sns.scatterplot(data=data, x=col1, y=col2)\n",
    "    else:\n",
    "        sns.scatterplot(data=data, x=col1, y=col2, hue=color_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14296e60-33a3-4b03-ace4-ab6f57b79552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avaliação de métricas\n",
    "def evaluate_metrics(y, y_pred):\n",
    "    #\n",
    "    mae = MAE(y, y_pred)\n",
    "    mse = MSE(y, y_pred)\n",
    "    rmse = mse ** (1/2)\n",
    "    r2 = R2(y, y_pred)\n",
    "    #\n",
    "    print(' Metricas da regresión')\n",
    "    print(f\" MAE: {mae:.2f}\")\n",
    "    print(f\" MSE: {mse:.2f}\")\n",
    "    print(f\" RMSE: {rmse:.2f}\")\n",
    "    print(f\" R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b81724a-dfa3-431a-88d0-84c07cb10bee",
   "metadata": {},
   "source": [
    ">## Construcción del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a7d22-f58f-4a0a-8c2d-058eb26d0ce2",
   "metadata": {},
   "source": [
    ">## Definición de las caracteristicas y el objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bce581-6ecc-4da7-8d4d-6f81e5f96aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição de grupos de variáveis (features) e objetivo\n",
    "features = ['NU_IDADE_N', 'FEBRE', 'TOSSE', 'DISPNEIA', 'DESC_RESP','SATURACAO', 'VOMITO', 'FADIGA', 'OUTRO_SIN', \n",
    "            'FATOR_RISC', 'CARDIOPATI','ASMA', 'DIABETES', 'OUT_MORBI','VACINA_COV', 'UTI']\n",
    "objetivo = 'EVOLUCAO'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33151d09-2639-4e3e-acf6-3e1788a01df5",
   "metadata": {},
   "source": [
    ">## Análisis exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b44eb1-1bdc-44c8-8ba9-17113b45bb28",
   "metadata": {},
   "source": [
    ">### Distribuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e337f7e-18eb-4836-aa34-9540e93e656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização de variavéis para identificar anomalias nos dados\n",
    "construir_distribuicoes(data,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880dbfd6-f4c9-49d6-a209-0b494603383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribuição estratificada\n",
    "construir_distribuicoes(data,features,objetivo,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38c754-a6f3-4928-a01c-6539e261dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz correlation de spearman\n",
    "corr_matrix = calcular_correlacao_numerica(data, features, corr_tipo='spearman')\n",
    "\n",
    "# Gerar mapa de calor\n",
    "plot_mapa_calor_corr(corr_matrix, 'Correlação de Spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b07c85-9959-43cd-8811-370fa6765657",
   "metadata": {},
   "source": [
    ">## División de los datos para entrenamiento y teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62290b04-9875-4e64-abac-759bcff1fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treino e teste: ok\n",
    "#X = dados.iloc[:,0:21]\n",
    "#y = dados.iloc[:,21]\n",
    "# Definindo conjunto X e Y\n",
    "X = data.drop(axis=1, columns=[objetivo]).copy()  # todas las columnas menos la columna ´EVOLUCAO´\n",
    "y = data[objetivo].copy()                         # copia columna objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be40c2-32e7-4d9c-8df1-7be443b5a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo a divisão estratificada 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03d547-ada8-4fe5-a500-2826fa7ffe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza os dados de treinamento (X_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85522e3f-10a1-4e2f-a9c1-a57f9babaea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7abafd0-4d0b-4c01-9895-57514932dbd0",
   "metadata": {},
   "source": [
    ">## Balanceamiento de los datos de entrenamiento y teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07666f8-9ca7-4857-8434-012b3e326cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando balaceamento da variavel objetivo\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60e0900-4c59-49d3-91b6-5ac7061138a6",
   "metadata": {},
   "source": [
    "># Construcción del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90992d18-6edd-4a69-8a78-cde849482bd6",
   "metadata": {},
   "source": [
    ">## Regresión Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5513f7-25ca-49fe-8696-2aa0ee29b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Lienar Regression - GridSearachCV\n",
    "def hiperparameters_LogisticR_gridSearchCV(X_train, y_train, X_test, y_test, params, filename, name):\n",
    "    # model\n",
    "    logReg_model = LogisticRegression(random_state=1000,penalty='elasticnet', solver='saga', max_iter=5000)\n",
    "    gs_logReg = GridSearchCV(estimator = logReg_model, param_grid= params, cv = 5,\n",
    "                         scoring=['f1', 'accuracy', 'recall', 'roc_auc',  'precision'],\n",
    "                         refit ='accuracy'\n",
    "                         )\n",
    "    \n",
    "    #predict\n",
    "    DTC = gs_logReg.fit(X_train, y_train)\n",
    "    #\n",
    "    #write file text\n",
    "    text0 ='File create by Jorge Zavaleta'\n",
    "    write_file_text(filename,text0)\n",
    "    #\n",
    "    # All results\n",
    "    means1 = DTC.cv_results_['mean_test_accuracy']\n",
    "    means2 = DTC.cv_results_['mean_test_precision']\n",
    "    means3 = DTC.cv_results_['mean_test_recall']\n",
    "    means4 = DTC.cv_results_['mean_test_f1']\n",
    "    means5 = DTC.cv_results_['mean_test_roc_auc']\n",
    "    stds = DTC.cv_results_['std_test_f1']\n",
    "    #\n",
    "    #\n",
    "    for mean1,mean2,mean3,mean4,mean5,std,params in zip(means1,means2,means3,means4,means5,stds,DTC.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean4, std * 2, params))\n",
    "        write_file_text(filename,' Acuracy: %0.3f ' % mean1)\n",
    "        write_file_text(filename,' Precision: %0.3f ' % mean2)\n",
    "        write_file_text(filename,' Recall: %0.3f ' % mean3)\n",
    "        write_file_text(filename,' F1-score: %0.3f ' % mean4)\n",
    "        write_file_text(filename,' ROC_AUC: %0.3f ' % mean5)\n",
    "        std = std*2\n",
    "        write_file_text(filename,' desvio: (+/-%0.03f) ' % std)\n",
    "        write_file_text(filename,' param: %s ' % params)\n",
    "        write_file_text(filename,'\\n')\n",
    "\n",
    "    # best parametes\n",
    "    print(' Mejores parametros encontrados:\\n', DTC.best_params_)\n",
    "    #\n",
    "    write_file_text(filename,' \\nMejores parametros encontrados: %s' % DTC.best_params_)\n",
    "    write_file_text(filename,'\\n')\n",
    "    #\n",
    "    # evaluate model performance\n",
    "    #Y\n",
    "    #y_true = y_test\n",
    "    y_pred = DTC.predict(X_test)\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    #\n",
    "    #print('Results on the test set logistic regression:')\n",
    "    print('Resultados del conjunto de teste usando a regresión logistica:')\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "    # Score method also evaluates accuracy for classification models.\n",
    "    # METRICAS\n",
    "    # accuracy\n",
    "    acc = accuracy_score(y_test, y_pred,normalize=True)\n",
    "    #precision\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    #fi-score\n",
    "    f1 = f1_score(y_test, y_pred, average='micro') \n",
    "    #recall/sensitivity   \t\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    #confusion matrix\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    # visualizar matriz de confusão\n",
    "    #print(pd.DataFrame(confusion_matrix(y_test,y_pred, labels=np.unique(y_test)), index=['Óbito-0', 'Cura-1'], columns=['Predito-0', 'Predito-1']))\n",
    "\n",
    "    print()\n",
    "    # print the scores\n",
    "    print(\" Accuracy:\", acc)\n",
    "    print(\" Precision:\", precision)\n",
    "    print(\" Recall/Sensitivity:\", recall)    \n",
    "    print(\" F1-score:\", f1)\n",
    "    print(\" cm:\\n\", cm)\n",
    "\n",
    "    #write scores in the file text\n",
    "    write_file_text(filename,' \\nTraining Accuracy : {:.3f}'.format(DTC.score(X_train, y_train)))\n",
    "    write_file_text(filename,' \\nTest Accuracy : {:.3f}'.format(DTC.score(X_test,y_test))+'\\n\\n')\n",
    "    #\n",
    "    write_file_text(filename,' Classification Report of Logistic Regression:\\n')\n",
    "    write_file_text(filename, classification_report(y_test,y_pred)+\"\\n\")\n",
    "    write_file_text(filename,' Resultado do test set:\\n')\n",
    "    write_file_text(filename,'\\n Accuracy: %0.03f' % acc)\n",
    "    write_file_text(filename,'\\n Precision: %0.03f' % precision)\n",
    "    write_file_text(filename,'\\n Recall: %0.03f' % recall)\n",
    "    write_file_text(filename,'\\n F1-score: %0.03f\\n' % f1)\n",
    "    write_file_text(filename,'\\n Matriz de confusao:\\n')\n",
    "    write_file_text(filename,' %0.03f ' % cm[0][0])\n",
    "    write_file_text(filename,' %0.03f \\n' % cm[0][1])\n",
    "    write_file_text(filename,' %0.03f ' % cm[1][0])\n",
    "    write_file_text(filename,' %0.03f ' % cm[1][1])\n",
    "    write_file_text(filename,'\\n\\n')\n",
    "    #\n",
    "    print()\n",
    "\n",
    "    # classes\n",
    "    class_names=[]\n",
    "    class_names.append(\"Óbito\")\n",
    "    class_names.append(\"Cura\")\n",
    "    \n",
    "    # plot the confusion matrix, without normalization\n",
    "    title1 = \"Matrix de confusión sin normalización\"\n",
    "    print('Graphic of the '+title1)\n",
    "    #\n",
    "    fig_name1 = 'data_mconfusao_LogReg'\n",
    "    display_cm(cm,class_names,title1,fig_name1)\n",
    "    \n",
    "    # Normalized confusion matrix\n",
    "    title2 = 'Matriz de confusión normalizada'\n",
    "    cm_normalized = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "    #\n",
    "    print(title2+'\\n')\n",
    "    print(' %0.03f ' % cm_normalized[0][0],' %0.03f ' % cm_normalized[0][1])\n",
    "    #print('%0.03f ' % cm_normalized[0][1])\n",
    "    print(' %0.03f ' % cm_normalized[1][0],' %0.03f ' % cm_normalized[1][1])\n",
    "    #print(' %0.03f ' % cm_normalized[1][1])\n",
    "    print('\\n')\n",
    "    # write file\n",
    "    write_file_text(filename,title2+'\\n')\n",
    "    write_file_text(filename,' %0.03f ' % cm_normalized[0][0])\n",
    "    write_file_text(filename,' %0.03f \\n' % cm_normalized[0][1])\n",
    "    write_file_text(filename,' %0.03f ' % cm_normalized[1][0])\n",
    "    write_file_text(filename,' %0.03f ' % cm_normalized[1][1])\n",
    "    write_file_text(filename,'\\n\\n')\n",
    "    #\n",
    "    print(' Gráfico de '+title2)\n",
    "    #\n",
    "    fig_name2 = 'data_m_confusao_LogReg_normalized'\n",
    "    display_cm(cm_normalized,class_names,title2,fig_name2)\n",
    "    \n",
    "    #\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr, tpr, _  = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #\n",
    "    print(' ROC curve (area = %0.2f)' % roc_auc+'\\n')\n",
    "    write_file_text(filename,' ROC curve (area = %0.2f)' % roc_auc+'\\n')\n",
    "    #\n",
    "    print(' Graphic of the ROC curve of Logistic Regression:\\n')\n",
    "    #\n",
    "    fig_name = 'data_curva_roc_LogReg'\n",
    "    plot_roc_curve(fpr,tpr,roc_auc,fig_name)\n",
    "    #\n",
    "    # Vamos calcular o resultado de probabilidade de predição do conjunto de treino\n",
    "    y_pred_train_proba = DTC.predict_proba(X_train)\n",
    "    #\n",
    "    # Vamos agora selecionar um resultado que previu como positivo\n",
    "    print('Probabilidad del modelo prever negativo -',100*y_pred_train_proba[3][0].round(2),'%.')\n",
    "    print('Probabilidad del modelo prever positivo -',100*y_pred_train_proba[3][1].round(2),'%.')\n",
    "    #\n",
    "    # Vamos calcular o resultado de probabilidade de predição do conjunto de treino\n",
    "    y_pred_test_proba = DTC.predict_proba(X_test)\n",
    "    #\n",
    "    # Vamos agora selecionar um resultado que previu como positivo\n",
    "    print('Test - Probabilidad del modelo prever negativo -',100*y_pred_test_proba[3][0].round(2),'%.')\n",
    "    print('test - Probabilidad del modelo prever positivo -',100*y_pred_test_proba[3][1].round(2),'%.')\n",
    "    #\n",
    "    print()\n",
    "    print(' Evaluación de los valores de las métricas en la Regresión Logística:\\n')\n",
    "    evaluate_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba468e8-7510-4641-996c-c3fe62634405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression GridSearchCV\n",
    "log_reg_name=['LR Vacinas COVID-19']\n",
    "log_reg_params={'C': [0.001, 0.01, 0.025, 0.1, 1, 5, 10],\n",
    "                'l1_ratio': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                'class_weight': ['balanced',None]}\n",
    "\n",
    "log_reg_filename = 'metricas/data_logistic_regression.txt'\n",
    "hiperparameters_LogisticR_gridSearchCV(X_train,y_train, X_test, y_test, log_reg_params, log_reg_filename, log_reg_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a06a3-59d8-49a3-8cf7-418a929158ae",
   "metadata": {},
   "source": [
    ">## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab17be25-f194-410e-8acf-d14a0ec61804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  GridSearachCV Shapley\n",
    "def hiperparameters_knn_gridSearchCV(X_train,y_train, X_test, y_test, params, filename, name):\n",
    "   \n",
    "     # knn - cria o modelo\n",
    "    knn_model = KNeighborsClassifier()\n",
    "\n",
    "    #\n",
    "    gs_knn = GridSearchCV(estimator = knn_model, param_grid=params,cv = 5,\n",
    "                      scoring=['f1', 'accuracy', 'recall', 'roc_auc', 'precision'],\n",
    "                      refit = 'accuracy')\n",
    "    # predict\n",
    "    DTC_KNN = gs_knn.fit(X_train,y_train)\n",
    "     \n",
    "    # write file text\n",
    "    text0 ='File create by Jorge Zavaleta'\n",
    "    write_file_text(filename,text0)\n",
    "\n",
    "    # All results\n",
    "    means1 = DTC_KNN.cv_results_['mean_test_accuracy']\n",
    "    means2 = DTC_KNN.cv_results_['mean_test_precision']\n",
    "    means3 = DTC_KNN.cv_results_['mean_test_recall']\n",
    "    means4 = DTC_KNN.cv_results_['mean_test_f1']\n",
    "    means5 = DTC_KNN.cv_results_['mean_test_roc_auc']\n",
    "    stds = DTC_KNN.cv_results_['std_test_f1']\n",
    "    #\n",
    "    for mean1,mean2,mean3,mean4,mean5,std,params in zip(means1,means2,means3,means4,means5,stds,DTC_KNN.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean4, std * 2, params))\n",
    "        write_file_text(filename,' Acurácia: %0.3f ' % mean1)\n",
    "        write_file_text(filename,' Precision: %0.3f ' % mean2)\n",
    "        write_file_text(filename,' Recall: %0.3f ' % mean3)\n",
    "        write_file_text(filename,' F1-score: %0.3f ' % mean4)\n",
    "        write_file_text(filename,' ROC_AUC: %0.3f ' % mean5)\n",
    "        std = std*2\n",
    "        write_file_text(filename,' desvio: (+/-%0.03f) ' % std)\n",
    "        write_file_text(filename,' param: %s ' % params)\n",
    "        write_file_text(filename,'\\n')\n",
    "\n",
    "    # best parametes\n",
    "    print(' Best parameters found for K-Nearest Neighbour:\\n', DTC_KNN.best_params_)\n",
    "    #\n",
    "    write_file_text(filename,' \\nBest parameters found for K-Nearest Neighbour: %s' % DTC_KNN.best_params_)\n",
    "    write_file_text(filename,'\\n')\n",
    "    #\n",
    "    # evaluate model performance\n",
    "    #Y\n",
    "    #y_true = y_test\n",
    "    y_pred = DTC_KNN.predict(X_test)\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    #\n",
    "    print('K-Nearest Neighbour - Results on the test set:')\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "    # Score method also evaluates accuracy for classification models.\n",
    "    # accuracy\n",
    "    acc = accuracy_score(y_test, y_pred,normalize=True)\n",
    "    #precision\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    #fi-score\n",
    "    f1 = f1_score(y_test, y_pred, average='micro') \n",
    "    #recall/sensitivity   \t\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    #confusion matrix\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    # visualizar matriz de confusão\n",
    "    \n",
    "    print()\n",
    "    # print the scores\n",
    "    print(\" Accuracy:\", acc)\n",
    "    print(\" Precision:\", precision)\n",
    "    print(\" Recall/Sensitivity:\", recall)    \n",
    "    print(\" F1-score:\", f1)\n",
    "    print(\" cm:\\n\", cm)\n",
    "\n",
    "    #write scores in the file text\n",
    "    write_file_text(filename,' \\nTraining Accuracy : {:.3f}'.format(DTC_KNN.score(X_train, y_train)))\n",
    "    write_file_text(filename,' \\nTest Accuracy : {:.3f}'.format(DTC_KNN.score(X_test,y_test))+'\\n\\n')\n",
    "    #\n",
    "    write_file_text(filename,' Classification Report for K-Nearest Neighbour:\\n')\n",
    "    write_file_text(filename, classification_report(y_test,y_pred)+\"\\n\")\n",
    "    write_file_text(filename,' Resultado do test set:\\n')\n",
    "    write_file_text(filename,'\\n Accuracy: %0.03f' % acc)\n",
    "    write_file_text(filename,'\\n Precision: %0.03f' % precision)\n",
    "    write_file_text(filename,'\\n Recall: %0.03f' % recall)\n",
    "    write_file_text(filename,'\\n F1-score: %0.03f\\n' % f1)\n",
    "    write_file_text(filename,'\\n Matriz de confusao:\\n')\n",
    "    write_file_text(filename,' %0.03f ' % cm[0][0])\n",
    "    write_file_text(filename,' %0.03f \\n' % cm[0][1])\n",
    "    write_file_text(filename,' %0.03f ' % cm[1][0])\n",
    "    write_file_text(filename,' %0.03f ' % cm[1][1])\n",
    "    write_file_text(filename,'\\n\\n')\n",
    "    #\n",
    "    print()\n",
    "\n",
    "    # classes\n",
    "    class_names=[]\n",
    "    class_names.append(\"Óbito\")\n",
    "    class_names.append(\"Cura\")\n",
    "    \n",
    "    # plot the confusion matrix, without normalization\n",
    "    title1 = \"Confusion matrix, without normalization\"\n",
    "    print('Graphic of the '+title1)\n",
    "    #\n",
    "    fig_name1 = 'data_knn_matriz_confusao'\n",
    "    display_cm(cm,class_names,title1,fig_name1)\n",
    "    \n",
    "    # Normalized confusion matrix\n",
    "    title2 = 'Matriz de confusión normalizada'\n",
    "    cm_normalized = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "    #\n",
    "    print(title2+'\\n')\n",
    "    print(' %0.03f ' % cm_normalized[0][0],' %0.03f ' % cm_normalized[0][1])\n",
    "    #print('%0.03f ' % cm_normalized[0][1])\n",
    "    print(' %0.03f ' % cm_normalized[1][0],' %0.03f ' % cm_normalized[1][1])\n",
    "    #print(' %0.03f ' % cm_normalized[1][1])\n",
    "    print('\\n')\n",
    "    # write file\n",
    "    write_file_text(filename,title2+'\\n')\n",
    "    write_file_text(filename,' %0.03f ' % cm_normalized[0][0])\n",
    "    write_file_text(filename,' %0.03f \\n' % cm_normalized[0][1])\n",
    "    write_file_text(filename,' %0.03f ' % cm_normalized[1][0])\n",
    "    write_file_text(filename,' %0.03f ' % cm_normalized[1][1])\n",
    "    write_file_text(filename,'\\n\\n')\n",
    "    #\n",
    "    print(' Graphic of the '+title2)\n",
    "    #\n",
    "    fig_name2 = 'data_knn_matriz_confusao_n'\n",
    "    display_cm(cm_normalized,class_names,title2,fig_name2)\n",
    "    \n",
    "    #\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr, tpr, _  = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #\n",
    "    print(' ROC curve (area = %0.2f)' % roc_auc+'\\n')\n",
    "    write_file_text(filename,' ROC curve (area = %0.2f)' % roc_auc+'\\n')\n",
    "    #\n",
    "    print(' Graphic of the ROC curve\\n')\n",
    "    #\n",
    "    fig_name = 'data_knn_curva_roc'\n",
    "    plot_roc_curve(fpr,tpr,roc_auc,fig_name)\n",
    "\n",
    "\n",
    "    # Vamos calcular o resultado de probabilidade de predição do conjunto de treino\n",
    "    y_pred_train_proba = DTC_KNN.predict_proba(X_train)\n",
    "    #\n",
    "    # Vamos agora selecionar um resultado que previu como positivo\n",
    "    print(' Probabilidad del modelo prever negativo -',100*y_pred_train_proba[3][0].round(2),'%.')\n",
    "    print(' Probabilidad del modelo prever positivo -',100*y_pred_train_proba[3][1].round(2),'%.')\n",
    "\n",
    "    # Vamos calcular o resultado de probabilidade de predição do conjunto de treino\n",
    "    y_pred_test_proba = DTC_KNN.predict_proba(X_test)\n",
    "    #\n",
    "    # Vamos agora selecionar um resultado que previu como positivo\n",
    "    print('Test - Probabilidad del modelo prever negativo -',100*y_pred_test_proba[3][0].round(2),'%.')\n",
    "    print('test - Probabilidad del modelo prever positivo -',100*y_pred_test_proba[3][1].round(2),'%.')\n",
    "    #\n",
    "    print()\n",
    "    print(' Evaluación de los valores de KNN:\\n')\n",
    "    evaluate_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd02610-cec8-4046-a2d7-d33f2ee2f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN\n",
    "knn_name=['KNN Vacinas COVID-19']\n",
    "#lr_params={'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, \n",
    "#                    10.0, 20, 50, 100, 500, 1000]}\n",
    "#\n",
    "knn_params = {'n_neighbors': np.arange(1, 50)}\n",
    "#knn_params = {'n_neighbors': [10]}\n",
    "#\n",
    "knn_filename = 'metricas/data_knn.txt'\n",
    "hiperparameters_knn_gridSearchCV(X_train,y_train, X_test, y_test, knn_params, knn_filename, knn_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f3a33-2486-42c9-aa0d-71b1fea674ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec3037-0181-4f0e-b943-93d84be39424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb83ca-637c-414a-b9f9-57f7d5b0ce59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3b47ea2-048f-4956-ad2d-0d135005dae1",
   "metadata": {},
   "source": [
    "> ## Grabar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d348bd-ac5f-4a9c-ba09-21d79e17daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataset to csv\n",
    "#def save_dataset(dataset,path,dataset_name):\n",
    "#    dataset.to_csv(path+dataset_name,sep=';',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5371a2d1-db63-4bce-a174-99011662a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = df_cura_obitos\n",
    "#path = 'data/'\n",
    "#dataset_name = 'curados_obitos_final.csv'\n",
    "#save_dataset(dataset,path,dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5132177-17df-4320-befe-0d5badfc0600",
   "metadata": {},
   "source": [
    "<center><b>© Jorge Zavaleta, 2024</b></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
